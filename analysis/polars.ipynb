{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal, stats\n",
    "from plotly import express as plx\n",
    "import json\n",
    "import csv\n",
    "\n",
    "from sklearn import linear_model\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "COINBASE_TICKERS = '../data/coinbase_tickers.txt'\n",
    "COINBASE_BOOKS = '../data/coinbase_books.txt'\n",
    "\n",
    "KRAKEN_TICKERS = '../data/kraken_tickers.txt'\n",
    "KRAKEN_BOOKS = '../data/kraken_books.txt'\n",
    "\n",
    "\n",
    "DEPTH = 100\n",
    "SCALE = int(1e8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the lag within the books as they update much faster than tickers do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of cb_bids 33548\n",
      "size of cb_asks 42740\n",
      "size of kk_bids 15935\n",
      "size of kk_asks 21757\n",
      "[String, UInt64, UInt64, UInt64]\n"
     ]
    }
   ],
   "source": [
    "schema = {\n",
    "    'ticker':pl.String,\n",
    "    'timestamp':pl.UInt64,\n",
    "    'type':pl.String,\n",
    "    'price':pl.UInt64,\n",
    "    'quantity':pl.UInt64\n",
    "}\n",
    "\n",
    "cb_book = (pl.read_csv(COINBASE_BOOKS, schema=schema))\n",
    "cb_bids = cb_book.filter(pl.col('type') == 'bid').drop('type')\n",
    "cb_asks = cb_book.filter(pl.col('type') == 'offer').drop('type')\n",
    "\n",
    "kk_book = (pl.scan_csv(KRAKEN_BOOKS, schema=schema)).collect()\n",
    "kk_bids = kk_book.filter(pl.col('type') == 'bid').drop('type')\n",
    "kk_asks = kk_book.filter(pl.col('type') == 'ask').drop('type')\n",
    "\n",
    "print(\"size of cb_bids\", cb_bids.height)\n",
    "print(\"size of cb_asks\", cb_asks.height)\n",
    "print(\"size of kk_bids\", kk_bids.height)\n",
    "print(\"size of kk_asks\", kk_asks.height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12370/12370 [00:07<00:00, 1565.93it/s]\n",
      "100%|██████████| 11855/11855 [00:08<00:00, 1435.28it/s]\n",
      "100%|██████████| 9617/9617 [00:06<00:00, 1592.65it/s]\n",
      "100%|██████████| 12125/12125 [00:07<00:00, 1572.06it/s]\n"
     ]
    }
   ],
   "source": [
    "def calculate_best(data, is_bid):\n",
    "\n",
    "    best_signal = []\n",
    "    all_ts = data.select('timestamp').unique().sort('timestamp')\n",
    "    first_ts = all_ts[0, \"timestamp\"]\n",
    "    curbook = data.filter(pl.col('timestamp') == first_ts)\n",
    "\n",
    "    for ts in tqdm(all_ts['timestamp']):\n",
    "        #update the book\n",
    "        signal = data.filter(pl.col('timestamp') == ts)\n",
    "        curbook = (curbook\n",
    "                   .join(signal.select(['price', 'quantity']), on='price', how='left', suffix='_new')\n",
    "                   .with_columns(pl.col('quantity_new').fill_null(pl.col('quantity')).alias('quantity'))\n",
    "                   .drop('quantity_new')\n",
    "                   .filter(pl.col('quantity') != 0)\n",
    "                   .sort('price', descending=is_bid)\n",
    "        )\n",
    "        # get best\n",
    "        minbook = curbook.head(DEPTH)\n",
    "        if not minbook.is_empty() and ts != first_ts:\n",
    "            best = {\n",
    "                'timestamp': ts,\n",
    "                'bid_price': curbook['price'][0],\n",
    "                'bid_quantity': curbook['quantity'][0]\n",
    "            } if is_bid else {\n",
    "                'timestamp': ts,\n",
    "                'ask_price': curbook['price'][0],\n",
    "                'ask_quantity': curbook['quantity'][0]\n",
    "            }\n",
    "            best_signal.append(best)\n",
    "\n",
    "\n",
    "    return pl.DataFrame(best_signal).cast(pl.UInt64)\n",
    "\n",
    "\n",
    "cb_bids_best = calculate_best(cb_bids, True)\n",
    "cb_asks_best = calculate_best(cb_asks, False)\n",
    "kk_bids_best = calculate_best(kk_bids, True)\n",
    "kk_asks_best = calculate_best(kk_asks, False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ffill(data):\n",
    "    # Convert 'timestamp' from milliseconds to a datetime column\n",
    "    data = data.with_columns(\n",
    "        pl.col('timestamp').cast(pl.Datetime('ms')).alias('datetime')\n",
    "    )\n",
    "    data = data.drop(pl.col('timestamp'))\n",
    "    # Generate a full range of datetime values at 1 ms intervals\n",
    "    start = data['datetime'].min()\n",
    "    end = data['datetime'].max()\n",
    "    full_range = pl.DataFrame({\n",
    "        'datetime':pl.datetime_range(start=start, end=end, interval='1ms', closed='both', eager=True)\n",
    "        }).cast(pl.Datetime('ms'))\n",
    "    \n",
    "    data = full_range.join(data, on='datetime', how='left')\n",
    "    data = (data\n",
    "            .fill_null(strategy='forward')\n",
    "            .with_columns(pl.col('datetime').dt.epoch(time_unit='ms').cast(pl.UInt64).alias('timestamp'))\n",
    "            .drop('datetime'))\n",
    "    return data\n",
    "\n",
    "cb_bids_best_ffill = ffill(cb_bids_best)\n",
    "cb_asks_best_ffill = ffill(cb_asks_best)\n",
    "kk_bids_best_ffill = ffill(kk_bids_best)\n",
    "kk_asks_best_ffill = ffill(cb_asks_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ffill_agregate(dataframes):\n",
    "    start = max(df['timestamp'].min() for df in dataframes)\n",
    "    end = min(df['timestamp'].max() for df in dataframes)\n",
    "\n",
    "    aligned_dfs = [df.filter((pl.col('timestamp') >= start) & (pl.col('timestamp') <= end)) for df in dataframes]\n",
    "    return aligned_dfs\n",
    "\n",
    "final = ffill_agregate([cb_bids_best_ffill,\n",
    "                      cb_asks_best_ffill,\n",
    "                      kk_bids_best_ffill,\n",
    "                      kk_asks_best_ffill])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_best_price(best_bids, best_ask):\n",
    "\n",
    "    ### super ghetto to prevent overflow, but since this is an dumb estimate of true price anyway it shouldnt really matter lol\n",
    "    df = (\n",
    "        best_bids\n",
    "        .join(best_ask, on=\"timestamp\", how=\"inner\")\n",
    "        .with_columns([\n",
    "            ((pl.col(\"bid_price\")/1000 * pl.col(\"bid_quantity\")/1000) + \n",
    "             (pl.col(\"ask_price\")/1000 * pl.col(\"ask_quantity\")/1000)).alias(\"weighted_value\"),\n",
    "            (pl.col(\"bid_quantity\") + pl.col(\"ask_quantity\")).alias(\"total_quantity\"),\n",
    "        ])\n",
    "        .with_columns((pl.col(\"weighted_value\") / pl.col(\"total_quantity\") * 1000000).cast(pl.UInt64).alias(\"price\"))\n",
    "        .select([\"timestamp\", \"price\"])\n",
    "    )\n",
    "    return df\n",
    "\n",
    "cb_price = weighted_best_price(final[0], final[1])\n",
    "kk_price = weighted_best_price(final[2], final[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_return(price):\n",
    "    df = (\n",
    "        price\n",
    "        .with_columns([\n",
    "            pl.col('price').log().diff().alias(\"log_return\")\n",
    "        ])\n",
    "        .select([\"timestamp\", \"log_return\"])\n",
    "    )\n",
    "    return df.filter(pl.col('log_return').is_null() != True)\n",
    "\n",
    "cb_lr = log_return(cb_price)\n",
    "kk_lr = log_return(kk_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: EVERYTHING ABOVE THIS NEEDS TO BE OPTIMIZED CUZ RN IT CAN'T RUN!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: indicators\n",
    "\n",
    " best-ask to best-bid price spread\n",
    " ask-bid imbalance (ask_vol - bid_vol) / (ask_vol + bid_vol)\n",
    "\n",
    "##### for MA, do for both best (best_signal_ffilled) and weighted avg (wavg_signal_ffileed)\n",
    "- MA (3 ms)\n",
    "- MA (10 ms)\n",
    "- MA (100 ms)\n",
    "- MA (1000 ms)\n",
    "- EMA (alpha = 0.01)\n",
    "- EMA (alpha = 0.05)\n",
    "- EMA (alpha = 0.10)\n",
    "- EMA (alpha = 0.33)\n",
    "- EMA (alpha = 0.67)\n",
    "- EMA (alpha = 0.90)\n",
    "\n",
    "- kalman filter\n",
    "\n",
    "*also I have a few ideas for slope interpolation of weighted avg to patch in gaps in noisy best_price, but we will ignore for now*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model pseudo code\n",
    "\n",
    "next, code up logistic regression to tell us if we should trade or not\n",
    "`LOGISTIC(indicators) => y(t)`\n",
    "or `LINEAR(indicators) => x(t), calculate z scores => y(t)`\n",
    "\n",
    "    x(T) = statistically segnificant signals at T timestep(forward filled)\n",
    "    x(T) is statsitically segniciant at T if X(T) > MEAN + Z*STD  \n",
    "    where MEAN & STD come from X(T-1), X(T-2), ... X(T-N)\n",
    "\n",
    "Y = `COINBASE_BEST_ASK(T+(LAG))` < the `KRAKEN_BEST_BID within (T+(LAG), T+(LAG)+(HOLDTIME)]`\n",
    "\n",
    "then optimize `HOLDTIME` and `Z` & `N` with the objective function (i'm thinking gridsearch to keep it simple)\n",
    "\n",
    "    OBJ = 0\n",
    "    WE_TRADE = Y(T) >= 0.5\n",
    "    if(WE_TRADE): \n",
    "      check if ask price @ T+LAG > bid price T1 @ T+LAG to T+LAG+HOLDTIME:\n",
    "          if so, (OBJ += (ASK_PRICE(T+LAG) - BID_PRICE(T+LAG+T1))\n",
    "          if not, (OBJ += ASK_PRICE(T+LAG) - BID_PRICE(T+LAG+T1))\n",
    "\n",
    "    MAX OBJ W.R.T `HOLDTIME` and `Z` & `N`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID-ing signiciant signals, ideally use logistical regression for this part\n",
    "window_size = 30  # law of large numbers\n",
    "# TODO, not price, its like cb_ask_price\n",
    "X1 = wavg_signal_ffilled['price'].rolling(window_size)\n",
    "mu = X1.mean(skipna=True)\n",
    "std = X1.std(skipna=True)\n",
    "z_th = 1\n",
    "\n",
    "zscores = X1.apply(lambda x: stats.zscore(x)[-1] if len(x) == window_size else np.nan)\n",
    "\n",
    "sig = zscores > z_th # peaks\n",
    "peaks = wavg_signal_ffilled['price'][sig]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "HOLDTIME = 100 # 100 ms\n",
    "LAG = 100 # 100 ms\n",
    "\n",
    "X = peaks.iloc[:-(HOLDTIME+LAG)]\n",
    "peakprice = best_signal_ffilled['kkbidprice'].rolling(HOLDTIME + LAG, min_periods=(HOLDTIME+LAG)).dropna().max()\n",
    "finalprice = best_signal_ffilled['kkbidprice'].iloc[HOLDTIME+LAG:]\n",
    "\n",
    "trade_ratio = (peakprice > finalprice).sum() / len(peakprice)\n",
    "trade_ratio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the following two cells into a method with parameters `HOLDTIME` and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(best_signal_ffilled['price_cb_asks'])\n",
    "plt.plot(best_signal_ffilled['price_cb_bids'])\n",
    "plt.ylim(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ask lag\n",
    "import plotly.graph_objects as go\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=best_signal_ffilled['timestamp'], y=best_signal_ffilled['price_' + \"cb\" + \"_asks\"]/SCALE, mode='lines', name='Coinbase'))\n",
    "fig.add_trace(go.Scatter(x=best_signal_ffilled['timestamp'], y=best_signal_ffilled['price_' + \"kk\" + \"_asks\"]/SCALE, mode='lines', name='Kraken'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot bids\n",
    "import plotly.graph_objects as go\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=best_signal_ffilled['timestamp'], y=best_signal_ffilled['price_' + \"cb\" + \"_bids\"]/SCALE, mode='lines', name='Coinbase'))\n",
    "fig.add_trace(go.Scatter(x=best_signal_ffilled['timestamp'], y=best_signal_ffilled['price_' + \"kk\" + \"_bids\"]/SCALE, mode='lines', name='Kraken'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import plotly.graph_objects as go\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=midpt_signal['timestamp'], y=midpt_signal['midpt_' + \"cb\"]/SCALE, mode='lines', name='Coinbase'))\n",
    "fig.add_trace(go.Scatter(x=midpt_signal['timestamp'], y=midpt_signal['midpt_' + \"kk\"]/SCALE, mode='lines', name='Kraken'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_delayed_crosscorrelation(s1, s2):\n",
    "    correlation = signal.correlate(s1, s2, mode='full', method='auto')\n",
    "    \n",
    "    max_corr_index = np.argmax(correlation)\n",
    "    max_corr_value = correlation[max_corr_index]\n",
    "    \n",
    "    delay = max_corr_index - (len(s1) - 1)\n",
    "    \n",
    "    return max_corr_value, delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('asks', max_delayed_crosscorrelation(best_signal_ffilled['price_cb_asks'], best_signal_ffilled['price_kk_asks']))\n",
    "print('bids', max_delayed_crosscorrelation(best_signal_ffilled['price_cb_bids'], best_signal_ffilled['price_kk_bids']))\n",
    "print('midpt', max_delayed_crosscorrelation(midpt_signal['midpt_cb'], midpt_signal['midpt_kk']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
