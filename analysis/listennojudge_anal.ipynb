{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import signal, stats\n",
    "from plotly import express as plx\n",
    "import json\n",
    "import csv\n",
    "\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !. ../secrets.sh && cd '../build' && ./scout_exe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "COINBASE_TICKERS = '../data/coinbase_tickers.txt'\n",
    "COINBASE_BOOKS = '../data/coinbase_books.txt'\n",
    "\n",
    "KRAKEN_TICKERS = '../data/kraken_tickers.txt'\n",
    "KRAKEN_BOOKS = '../data/kraken_books.txt'\n",
    "\n",
    "\n",
    "DEPTH = 100\n",
    "SCALE = int(1e8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the lag within the books as they update much faster than tickers do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coinbase\n",
    "\n",
    "cb_book = pd.read_csv(COINBASE_BOOKS, header=None)\n",
    "cb_book.columns = ['ticker', 'timestamp', 'type', 'price', 'quantity']\n",
    "cb_bids = cb_book[cb_book.type == 'bid'].drop('type',axis=1)\n",
    "cb_asks = cb_book[cb_book.type == 'offer'].drop('type',axis=1)\n",
    "\n",
    "# kraken\n",
    "\n",
    "kk_book = pd.read_csv(KRAKEN_BOOKS, header=None)\n",
    "kk_book.columns = ['ticker', 'timestamp', 'type', 'price', 'quantity']\n",
    "kk_book = kk_book[kk_book['timestamp'] != 0]\n",
    "kk_bids = kk_book[kk_book.type == 'bid'].drop('type',axis=1)\n",
    "kk_asks = kk_book[kk_book.type == 'ask'].drop('type',axis=1)\n",
    "\n",
    "\n",
    "print(\"size of cb_bids\", len(cb_bids))\n",
    "print(\"size of cb_asks\", len(cb_asks))\n",
    "print(\"size of kk_bids\", len(kk_bids))\n",
    "print(\"size of kk_asks\", len(kk_asks))\n",
    "\n",
    "signal_ind = {'cb_bids': 0, 'cb_asks': 1, 'kk_bids': 2, 'kk_asks': 3}\n",
    "books = [cb_bids, cb_asks, kk_bids, kk_asks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use to test code so it doesn't take forver to run\n",
    "for sig,ii in signal_ind.items():\n",
    "    books[ii] = books[ii].iloc[0:2000,:]\n",
    "books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_signal = [pd.DataFrame(columns=['timestamp', 'price', 'quantity']) for x in signal_ind.keys()]\n",
    "wavg_signal = [pd.DataFrame(columns=['timestamp', 'price', 'total_volume']) for x in signal_ind.keys()]\n",
    "price_signal = [pd.DataFrame(columns=['timestamp', 'std', 'median', 'spread']) for x in signal_ind.keys()]\n",
    "\n",
    "for sig, ii in signal_ind.items():\n",
    "    is_bid = ii % 2 == 0\n",
    "    allts = np.sort(books[ii]['timestamp'].unique())\n",
    "    firstts = allts[0]\n",
    "    at_firstts = books[ii]['timestamp'] == firstts\n",
    "\n",
    "    curbook = books[ii][at_firstts].copy()\n",
    "    # complete_book = pd.DataFrame()\n",
    "    # this can probs easily be solved by using a groupby, im so dumb\n",
    "    for ts in allts:\n",
    "        at_ts = books[ii]['timestamp'] == ts\n",
    "        sig_at_ts = books[ii][at_ts]\n",
    "\n",
    "        merged = pd.merge(sig_at_ts[['price', 'quantity']], curbook, on='price', how='left', suffixes=('_old', ''))\n",
    "        merged['quantity']=merged['quantity'].fillna(merged['quantity_old'])\n",
    "        curbook = merged.drop('quantity_old', axis=1)\n",
    "        curbook['timestamp'] = ts\n",
    "        curbook = curbook[curbook['quantity'] != 0]\n",
    "        curbook = curbook.sort_values('price', ascending=(not is_bid))\n",
    "        \n",
    "        # complete_book = pd.concat([complete_book,curbook.iloc[:DEPTH]])\n",
    "\n",
    "        if(not curbook['price'].empty):\n",
    "            minbook = curbook.iloc[0:DEPTH, :]\n",
    "            wavg_signal[ii].loc[len(wavg_signal[ii])] = [ts, \n",
    "                                                         (minbook['price'] * minbook['quantity']).sum() / minbook['quantity'].sum(), \n",
    "                                                         minbook['quantity'].sum()]\n",
    "            best_signal[ii].loc[len(best_signal[ii])] = [ts, curbook['price'].iloc[0], curbook['quantity'].iloc[0]]\n",
    "            price_signal[ii].loc[len(price_signal[ii])] = [ts, \n",
    "                                                           np.std(minbook['price']),\n",
    "                                                           minbook['price'].iloc[int(len(minbook['price'])/2)],\n",
    "                                                           np.abs(np.min(minbook['price']) - np.max(minbook['price']))]\n",
    "\n",
    "\n",
    "    wavg_signal[ii] = wavg_signal[ii][wavg_signal[ii]['price'] > 0]\n",
    "# best_signal\n",
    "# wavg_signal\n",
    "# price_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ffill_df(dfs, sigkeys):\n",
    "    ffilled_dfs = []\n",
    "    for sig,df in zip(sigkeys,dfs):\n",
    "        df.index = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "        df = df.drop(['timestamp'], axis=1)\n",
    "        df.index.name = 'date'\n",
    "        df = df.resample('1ms').ffill() \n",
    "        ffilled_dfs.append(df)\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    ffilled = ffilled_dfs[i].rename(columns=lambda col: col + \"_\" + sigkeys[i] if col != \"date\" else col)\n",
    "    i += 1\n",
    "    while i < len(sigkeys):\n",
    "        current_df = ffilled_dfs[i].rename(columns=lambda col: col + \"_\" + sigkeys[i] if col != \"date\" else col)\n",
    "        ffilled = pd.merge(\n",
    "            ffilled,\n",
    "            current_df,\n",
    "            on='date',\n",
    "            how='inner'\n",
    "        )\n",
    "        i += 1\n",
    "\n",
    "    ffilled['timestamp'] = ffilled.index.view('int64') / 10**9\n",
    "    ffilled['timestamp'] = ffilled['timestamp'] - np.min(ffilled['timestamp'])\n",
    "    return ffilled\n",
    "\n",
    "\n",
    "best_signal_ffilled = ffill_df(best_signal, list(signal_ind.keys()))\n",
    "wavg_signal_ffilled = ffill_df(wavg_signal, list(signal_ind.keys()))\n",
    "price_signal_ffilled = ffill_df(price_signal, list(signal_ind.keys()))\n",
    "\n",
    "best_signal_ffilled.to_csv('best_signal_ffilled.csv')\n",
    "wavg_signal_ffilled.to_csv('wavg_signal_ffilled.csv')\n",
    "price_signal_ffilled.to_csv('price_signal_ffilled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_signal_ffilled = pd.read_csv('best_signal_ffilled.csv')\n",
    "wavg_signal_ffilled = pd.read_csv('wavg_signal_ffilled.csv')\n",
    "price_signal_ffilled = pd.read_csv('price_signal_ffilled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: EVERYTHING ABOVE THIS NEEDS TO BE OPTIMIZED CUZ RN IT CAN'T RUN!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: indicators\n",
    "\n",
    " best-ask to best-bid price spread\n",
    " ask-bid imbalance (ask_vol - bid_vol) / (ask_vol + bid_vol)\n",
    "\n",
    "##### for MA, do for both best (best_signal_ffilled) and weighted avg (wavg_signal_ffileed)\n",
    "- MA (3 ms)\n",
    "- MA (10 ms)\n",
    "- MA (100 ms)\n",
    "- MA (1000 ms)\n",
    "- EMA (alpha = 0.01)\n",
    "- EMA (alpha = 0.05)\n",
    "- EMA (alpha = 0.10)\n",
    "- EMA (alpha = 0.33)\n",
    "- EMA (alpha = 0.67)\n",
    "- EMA (alpha = 0.90)\n",
    "\n",
    "- kalman filter\n",
    "\n",
    "*also I have a few ideas for slope interpolation of weighted avg to patch in gaps in noisy best_price, but we will ignore for now*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model pseudo code\n",
    "\n",
    "next, code up logistic regression to tell us if we should trade or not\n",
    "`LOGISTIC(indicators) => y(t)`\n",
    "or `LINEAR(indicators) => x(t), calculate z scores => y(t)`\n",
    "\n",
    "    x(T) = statistically segnificant signals at T timestep(forward filled)\n",
    "    x(T) is statsitically segniciant at T if X(T) > MEAN + Z*STD  \n",
    "    where MEAN & STD come from X(T-1), X(T-2), ... X(T-N)\n",
    "\n",
    "Y = `COINBASE_BEST_ASK(T+(LAG))` < the `KRAKEN_BEST_BID within (T+(LAG), T+(LAG)+(HOLDTIME)]`\n",
    "\n",
    "then optimize `HOLDTIME` and `Z` & `N` with the objective function (i'm thinking gridsearch to keep it simple)\n",
    "\n",
    "    OBJ = 0\n",
    "    WE_TRADE = Y(T) >= 0.5\n",
    "    if(WE_TRADE): \n",
    "      check if ask price @ T+LAG > bid price T1 @ T+LAG to T+LAG+HOLDTIME:\n",
    "          if so, (OBJ += (ASK_PRICE(T+LAG) - BID_PRICE(T+LAG+T1))\n",
    "          if not, (OBJ += ASK_PRICE(T+LAG) - BID_PRICE(T+LAG+T1))\n",
    "\n",
    "    MAX OBJ W.R.T `HOLDTIME` and `Z` & `N`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID-ing signiciant signals, ideally use logistical regression for this part\n",
    "window_size = 30  # law of large numbers\n",
    "# TODO, not price, its like cb_ask_price\n",
    "X1 = wavg_signal_ffilled['price'].rolling(window_size)\n",
    "mu = X1.mean(skipna=True)\n",
    "std = X1.std(skipna=True)\n",
    "z_th = 1\n",
    "\n",
    "zscores = X1.apply(lambda x: stats.zscore(x)[-1] if len(x) == window_size else np.nan)\n",
    "\n",
    "sig = zscores > z_th # peaks\n",
    "peaks = wavg_signal_ffilled['price'][sig]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "HOLDTIME = 100 # 100 ms\n",
    "LAG = 100 # 100 ms\n",
    "\n",
    "X = peaks.iloc[:-(HOLDTIME+LAG)]\n",
    "peakprice = best_signal_ffilled['kkbidprice'].rolling(HOLDTIME + LAG, min_periods=(HOLDTIME+LAG)).dropna().max()\n",
    "finalprice = best_signal_ffilled['kkbidprice'].iloc[HOLDTIME+LAG:]\n",
    "\n",
    "trade_ratio = (peakprice > finalprice).sum() / len(peakprice)\n",
    "trade_ratio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the following two cells into a method with parameters `HOLDTIME` and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(best_signal_ffilled['price_cb_asks'])\n",
    "plt.plot(best_signal_ffilled['price_cb_bids'])\n",
    "plt.ylim(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ask lag\n",
    "import plotly.graph_objects as go\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=best_signal_ffilled['timestamp'], y=best_signal_ffilled['price_' + \"cb\" + \"_asks\"]/SCALE, mode='lines', name='Coinbase'))\n",
    "fig.add_trace(go.Scatter(x=best_signal_ffilled['timestamp'], y=best_signal_ffilled['price_' + \"kk\" + \"_asks\"]/SCALE, mode='lines', name='Kraken'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot bids\n",
    "import plotly.graph_objects as go\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=best_signal_ffilled['timestamp'], y=best_signal_ffilled['price_' + \"cb\" + \"_bids\"]/SCALE, mode='lines', name='Coinbase'))\n",
    "fig.add_trace(go.Scatter(x=best_signal_ffilled['timestamp'], y=best_signal_ffilled['price_' + \"kk\" + \"_bids\"]/SCALE, mode='lines', name='Kraken'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import plotly.graph_objects as go\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=midpt_signal['timestamp'], y=midpt_signal['midpt_' + \"cb\"]/SCALE, mode='lines', name='Coinbase'))\n",
    "fig.add_trace(go.Scatter(x=midpt_signal['timestamp'], y=midpt_signal['midpt_' + \"kk\"]/SCALE, mode='lines', name='Kraken'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_delayed_crosscorrelation(s1, s2):\n",
    "    correlation = signal.correlate(s1, s2, mode='full', method='auto')\n",
    "    \n",
    "    max_corr_index = np.argmax(correlation)\n",
    "    max_corr_value = correlation[max_corr_index]\n",
    "    \n",
    "    delay = max_corr_index - (len(s1) - 1)\n",
    "    \n",
    "    return max_corr_value, delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('asks', max_delayed_crosscorrelation(best_signal_ffilled['price_cb_asks'], best_signal_ffilled['price_kk_asks']))\n",
    "print('bids', max_delayed_crosscorrelation(best_signal_ffilled['price_cb_bids'], best_signal_ffilled['price_kk_bids']))\n",
    "print('midpt', max_delayed_crosscorrelation(midpt_signal['midpt_cb'], midpt_signal['midpt_kk']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
